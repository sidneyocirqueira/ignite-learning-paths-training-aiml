{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"evalue":"Error: Jupyter server crashed. Unable to connect. \r\nError code from jupyter: 1","output_type":"error"}],"source":["import azureml\n","from azureml.core import Workspace, Experiment, Datastore, Environment\n","from azureml.core.runconfig import RunConfiguration\n","from azureml.data.datapath import DataPath, DataPathComputeBinding\n","from azureml.data.data_reference import DataReference\n","from azureml.core.compute import ComputeTarget, AmlCompute\n","from azureml.core.compute_target import ComputeTargetException\n","from azureml.pipeline.core import Pipeline, PipelineData, PipelineParameter\n","from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n","from azureml.widgets import RunDetails\n","from azureml.train.estimator import Estimator\n","import os\n","\n","print(\"Azure ML SDK Version: \", azureml.core.VERSION)"]},{"cell_type":"markdown","metadata":{},"source":["# Setup Variables"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["os.environ['STORAGE_ACCOUNT_KEY'] = 'bQAcA/nfOxQCn1zQX/3U/KwG51o7xLIYQsCBlIqaFJ6w6IPn6Rp7IKBtL84n+fbdpWhyhFdNzFN3CWk/XH5mgQ=='"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["datastorename='seerdata'\n","datastorepath='hardware'\n","containername='seer-container'\n","storageaccountname='mlopsws6982005979'\n","storageaccountkey=os.environ.get('STORAGE_ACCOUNT_KEY')\n","computetarget='mlopscluster'"]},{"cell_type":"markdown","metadata":{},"source":["# Register/Reference a Datastore"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'workspaceblobstore': <azureml.data.azure_storage_datastore.AzureBlobDatastore object at 0x7f926c220630>, 'workspacefilestore': <azureml.data.azure_storage_datastore.AzureFileDatastore object at 0x7f926c228048>, 'damoseerdata': <azureml.data.azure_storage_datastore.AzureBlobDatastore object at 0x7f926c228550>}\n"]}],"source":["# workspace\n","ws = Workspace.from_config(\n","    path='./azureml-config.json')\n","print(ws.datastores)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":["# See if that datastore already exists and unregister it if so\n","try:\n","    datastore = ws.datastores[datastorename]\n","    print ('Unregistering existing datastore')\n","    datastore.unregister()\n","except:\n","    print ('Data store doesn\\'t exist, no need to remove')\n","finally:\n","    # register the datastore\n","    datastore = Datastore.register_azure_blob_container(workspace=ws,\n","                                        datastore_name=datastorename,\n","                                        container_name=containername,\n","                                        account_name=storageaccountname,\n","                                        account_key=storageaccountkey,\n","                                        create_if_not_exists=True)\n","\n","print('Datastore registered: ', datastore)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<azureml.data.azure_storage_datastore.AzureBlobDatastore object at 0x7f926c220278>\n","AmlCompute(workspace=Workspace.create(name='damo-mlworkspace', subscription_id='bc202ec2-54ef-4576-b7fb-a961c983398e', resource_group='damo-aiml'), name=damoseercompute, id=/subscriptions/bc202ec2-54ef-4576-b7fb-a961c983398e/resourceGroups/damo-aiml/providers/Microsoft.MachineLearningServices/workspaces/damo-mlworkspace/computes/damoseercompute, type=AmlCompute, provisioning_state=Succeeded, location=australiaeast, tags=None)\n"]}],"source":["# data\n","datastore = ws.datastores['seerdata']\n","datareference = DataReference(datastore=datastore, \n","                    data_reference_name=\"seerdata\", \n","                    path_on_datastore=datastorepath)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Create Compute Resources"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["try:\n","    cpu_cluster = ComputeTarget(workspace=ws, name=computetarget)\n","    print('Found existing cluster, use it.')\n","except ComputeTargetException:\n","    compute_config = AmlCompute.provisioning_configuration(\n","        vm_size='STANDARD_NC6', \n","        min_nodes=1, \n","        max_nodes=4)\n","    cpu_cluster = ComputeTarget.create(ws, computetarget, compute_config)\n","\n","cpu_cluster.wait_for_completion(show_output=True)\n","compute = ws.compute_targets[computetarget]\n","\n","print('Compute registered: ', compute)"]},{"cell_type":"markdown","metadata":{},"source":["# Define Pipeline!\n","\n","The following will be created and then run:\n","\n","  1. Pipeline Parameters\n","  2. Data Process Step\n","  3. Training Step\n","  4. Model Registration Step\n","  5. Pipeline registration\n","  6. Submit the pipeline for execution\n"]},{"cell_type":"markdown","metadata":{},"source":["## Pipeline Parameters\n","We need to tell the Pipeline what it needs to learn to see!"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(<azureml.pipeline.core.graph.PipelineParameter object at 0x7f926c23e320>, <azureml.data.datapath.DataPathComputeBinding object at 0x7f926c23e358>)\n"]}],"source":["datapath = DataPath(datastore=datastore, path_on_datastore=datastorepath)\n","data_path_pipeline_param = (PipelineParameter(name=\"data\", \n","                                             default_value=datapath), \n","                                             DataPathComputeBinding(mode='mount'))\n","print(data_path_pipeline_param)\n","\n","# Configuration for data prep and training steps\n","dataprepEnvironment = Environment.from_pip_requirements('dataprepenv', 'requirements-dataprepandtraining.txt')\n","dataprepRunConfig = RunConfiguration()\n","dataprepRunConfig.environment = dataprepEnvironment"]},{"cell_type":"markdown","metadata":{},"source":["## Data Process Step"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<azureml.pipeline.steps.python_script_step.PythonScriptStep object at 0x7f926c2205f8>\n"]}],"source":["seer_tfrecords = PipelineData(\n","    \"tfrecords_set\",\n","    datastore=datastore,\n","    is_directory=True\n",")\n","\n","prepStep = PythonScriptStep(\n","    'parse.py',\n","    source_directory='.',\n","    name='Data Preparation',\n","    compute_target=compute,\n","    arguments=[\"--source_path\", data_path_pipeline_param, \"--target_path\", seer_tfrecords],\n","    runconfig=dataprepRunConfig,\n","    inputs=[data_path_pipeline_param],\n","    outputs=[seer_tfrecords]\n",")\n","\n","print(prepStep)"]},{"cell_type":"markdown","metadata":{},"source":["## Training Step"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n","WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n"]},{"name":"stdout","output_type":"stream","text":["<azureml.pipeline.steps.estimator_step.EstimatorStep object at 0x7f926c228320>\n"]}],"source":["seer_training = PipelineData(\n","    \"train\",\n","    datastore=datastore,\n","    is_directory=True\n",")\n","\n","train = Estimator(source_directory='.',\n","                    compute_target=compute,\n","                    entry_script='train.py',\n","                    pip_requirements_file='requirements-dataprepandtraining.txt')\n","\n","trainStep = EstimatorStep(\n","    name='Model Training',\n","    estimator=train,\n","    estimator_entry_script_arguments=[\"--source_path\", seer_tfrecords, \n","                                    \"--target_path\", seer_training,\n","                                    \"--epochs\", 5,\n","                                    \"--batch\", 10,\n","                                    \"--lr\", 0.001],\n","    inputs=[seer_tfrecords],\n","    outputs=[seer_training],\n","    compute_target=compute\n",")\n","\n","print(trainStep)"]},{"cell_type":"markdown","metadata":{},"source":["# Register Model Step"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<azureml.pipeline.steps.python_script_step.PythonScriptStep object at 0x7f926c23ebe0>\n"]}],"source":["registerEnvironment = Environment.from_pip_requirements('registerenv', 'requirements-registration.txt')\n","registerRunConfig = RunConfiguration()\n","registerRunConfig.environment = registerEnvironment\n","\n","seer_model = PipelineData(\n","    \"model\",\n","    datastore=datastore,\n","    is_directory=True\n",")\n","\n","registerStep = PythonScriptStep(\n","    'register.py',\n","    source_directory='.',\n","    name='Model Registration',\n","    arguments=[\"--source_path\", seer_training, \n","               \"--target_path\", seer_model],\n","    inputs=[seer_training],\n","    outputs=[seer_model],\n","    compute_target=compute,\n","    runconfig=registerRunConfig\n",")\n","\n","print(registerStep)"]},{"cell_type":"markdown","metadata":{},"source":["## Create and publish the Pipeline"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n","WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n","WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n"]},{"name":"stdout","output_type":"stream","text":["Created step Data Preparation [245a32d6][bb74677f-84f0-4646-a63c-55d831860987], (This step will run and generate new outputs)\n","Created step Model Training [ff56996a][884edd1b-e363-4a0d-b5e9-6d3a90fb0237], (This step will run and generate new outputs)\n","Created step Model Registration [df06b3ce][13374cdd-5994-426e-983f-4c0de03d2c1b], (This step will run and generate new outputs)\n","Created data reference damoseerdata_daf26998 for StepId [999c4b39][a1dc6fcc-1bc5-4644-859b-9cc91cdfb1d7], (Consumers of this data will generate new runs.)\n"]}],"source":["pipeline = Pipeline(workspace=ws, steps=[prepStep, trainStep, registerStep])\n","\n","published_pipeline = pipeline.publish(\n","    name=\"Seer Pipeline\", \n","    description=\"Transfer learned image classifier. Uses folders as labels.\")"]},{"cell_type":"code","execution_count":9,"metadata":{"scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Run created with ID:  7103c1bc-807a-4e25-8874-e578511eb035\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c7d9e1953c404a50b50970762b36b757","version_major":2,"version_minor":0},"text/plain":["A Jupyter Widget"]},"metadata":{},"output_type":"display_data"}],"source":["# Submit the pipeline to be run\n","pipeline_run = Experiment(ws, 'seer',).submit(published_pipeline)\n","print('Run created with ID: ', pipeline_run.id)\n","\n","RunDetails(pipeline_run).show()"]}],"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"nbformat":4,"nbformat_minor":2}